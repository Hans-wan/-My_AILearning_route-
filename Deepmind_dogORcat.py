# m4_cat_dog_trainer.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.datasets import ImageFolder
import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
import time
import json
from tqdm import tqdm

class M4CatDogTrainer:
    def __init__(self):
        # æ£€æŸ¥å¹¶è®¾ç½®MPSè®¾å¤‡
        if torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("ğŸ‰ M4 GPU (MPS) å¯ç”¨ï¼Œä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒ")
        else:
            self.device = torch.device("cpu")
            print("âš ï¸  MPSä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        
        # M4ä¼˜åŒ–å‚æ•°
        self.batch_size = 32  # M4å†…å­˜è¾ƒå¤§ï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch size
        self.num_epochs = 50
        self.learning_rate = 0.001
        
        # åˆ›å»ºæ•°æ®ç›®å½•
        self.setup_directories()
        
        # æ•°æ®å˜æ¢ï¼ˆé’ˆå¯¹M4ä¼˜åŒ–ï¼‰
        self.train_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(0.5),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        self.val_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])

    def setup_directories(self):
        """åˆ›å»ºæ•°æ®ç›®å½•ç»“æ„"""
        directories = [
            'data/train/cats',
            'data/train/dogs', 
            'data/val/cats',
            'data/val/dogs'
        ]
        
        for dir_path in directories:
            os.makedirs(dir_path, exist_ok=True)
        
        print("ğŸ“ æ•°æ®ç›®å½•ç»“æ„å·²åˆ›å»º")
    def create_model(self, num_classes=2):
        """åˆ›å»ºé’ˆå¯¹M4ä¼˜åŒ–çš„æ¨¡å‹"""
        # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet50ï¼Œæ›´å¤§çš„æ¨¡å‹åœ¨M4ä¸Šä¹Ÿèƒ½å¾ˆå¥½è¿è¡Œ
        model = models.resnet50(pretrained=True)
        
        # å†»ç»“å‰é¢å±‚ï¼Œåªè®­ç»ƒæœ€åå‡ å±‚
        for param in model.parameters():
            param.requires_grad = False
        
        # è§£å†»æœ€åä¸¤ä¸ªå±‚
        for param in model.layer4.parameters():
            param.requires_grad = True
        
        # æ›¿æ¢åˆ†ç±»å™¨
        in_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(in_features, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )
        
        return model.to(self.device)

    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("ğŸ“Š åŠ è½½æ•°æ®...")
        
        try:
            train_dataset = ImageFolder('data/train', transform=self.train_transform)
            val_dataset = ImageFolder('data/val', transform=self.val_transform)
            
            # ä½¿ç”¨M4ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨
            train_loader = DataLoader(
                train_dataset, 
                batch_size=self.batch_size, 
                shuffle=True, 
                num_workers=2,  # M4å¯ä»¥å¤„ç†æ›´å¤šworker
                pin_memory=True  # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
            )
            
            val_loader = DataLoader(
                val_dataset, 
                batch_size=self.batch_size, 
                shuffle=False,
                num_workers=2,
                pin_memory=True
            )
            
            print(f"âœ… è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
            print(f"âœ… éªŒè¯æ ·æœ¬: {len(val_dataset)}")
            print(f"âœ… ç±»åˆ«: {train_dataset.classes}")
            
            return train_loader, val_loader, train_dataset.classes
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None, None, None

    def train(self):
        """è®­ç»ƒæ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        
        # åŠ è½½æ•°æ®
        train_loader, val_loader, class_names = self.load_data()
        if train_loader is None:
            return
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_model(len(class_names))
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.AdamW(
            filter(lambda p: p.requires_grad, model.parameters()), 
            lr=self.learning_rate,
            weight_decay=0.01
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.num_epochs)
        
        # è®°å½•è®­ç»ƒè¿‡ç¨‹
        train_losses = []
        val_accuracies = []
        best_accuracy = 0.0
        
        # å¼€å§‹è®­ç»ƒè®¡æ—¶
        start_time = time.time()
        
        for epoch in range(self.num_epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            running_loss = 0.0
            correct_train = 0
            total_train = 0
            
            train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{self.num_epochs} [è®­ç»ƒ]')
            
            for images, labels in train_bar:
                images, labels = images.to(self.device, non_blocking=True), labels.to(self.device, non_blocking=True)
                
                # å‰å‘ä¼ æ’­
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                # ç»Ÿè®¡
                running_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total_train += labels.size(0)
                correct_train += (predicted == labels).sum().item()
                
                # æ›´æ–°è¿›åº¦æ¡
                train_bar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{100 * correct_train / total_train:.2f}%'
                })
            
            # éªŒè¯é˜¶æ®µ
            model.eval()
            correct_val = 0
            total_val = 0
            
            val_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{self.num_epochs} [éªŒè¯]')
            
            with torch.no_grad():
                for images, labels in val_bar:
                    images, labels = images.to(self.device, non_blocking=True), labels.to(self.device, non_blocking=True)
                    outputs = model(images)
                    _, predicted = torch.max(outputs.data, 1)
                    total_val += labels.size(0)
                    correct_val += (predicted == labels).sum().item()
                    
                    val_bar.set_postfix({
                        'Acc': f'{100 * correct_val / total_val:.2f}%'
                    })
            
            # è®¡ç®—æŒ‡æ ‡
            train_accuracy = 100 * correct_train / total_train
            val_accuracy = 100 * correct_val / total_val
            avg_loss = running_loss / len(train_loader)
            
            train_losses.append(avg_loss)
            val_accuracies.append(val_accuracy)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            print(f'\nğŸ“Š Epoch {epoch+1} ç»“æœ:')
            print(f'   è®­ç»ƒæŸå¤±: {avg_loss:.4f}')
            print(f'   è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy:.2f}%')
            print(f'   éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.2f}%')
            print(f'   å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.2e}')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'accuracy': best_accuracy,
                    'class_names': class_names
                }, 'best_m4_model.pth')
                print(f'   ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {best_accuracy:.2f}%')
            
            print('-' * 50)
        
        # è®­ç»ƒå®Œæˆ
        training_time = time.time() - start_time
        print(f'âœ… è®­ç»ƒå®Œæˆ! æ€»æ—¶é—´: {training_time/60:.2f} åˆ†é’Ÿ')
        print(f'ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_accuracy:.2f}%')
        
        return model, train_losses, val_accuracies

    def plot_results(self, train_losses, val_accuracies):
        """ç»˜åˆ¶è®­ç»ƒç»“æœ"""
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        plt.plot(train_losses)
        plt.title('è®­ç»ƒæŸå¤±')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True)
        
        plt.subplot(1, 3, 2)
        plt.plot(val_accuracies)
        plt.title('éªŒè¯å‡†ç¡®ç‡')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.grid(True)
        
        # æ·»åŠ è®­ç»ƒä¿¡æ¯
        plt.subplot(1, 3, 3)
        plt.axis('off')
        info_text = f"""è®­ç»ƒä¿¡æ¯:
è®¾å¤‡: {self.device}
Batch Size: {self.batch_size}
æœ€ä½³å‡†ç¡®ç‡: {max(val_accuracies):.2f}%
æœ€ç»ˆæŸå¤±: {train_losses[-1]:.4f}"""
        plt.text(0.1, 0.9, info_text, fontsize=12, verticalalignment='top')
        
        plt.tight_layout()
        plt.savefig('m4_training_results.png', dpi=300, bbox_inches='tight')
        plt.show()

class M4Predictor:
    def __init__(self, model_path='best_m4_model.pth'):
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
        
        # åŠ è½½æ¨¡å‹
        checkpoint = torch.load(model_path, map_location=self.device)
        self.class_names = checkpoint['class_names']
        
        self.model = models.resnet50(pretrained=False)
        in_features = self.model.fc.in_features
        self.model.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(in_features, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, len(self.class_names))
        )
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # æ•°æ®å˜æ¢
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")

    def predict(self, image_path):
        """é¢„æµ‹å•å¼ å›¾ç‰‡"""
        # åŠ è½½å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')
        original_image = np.array(image)
        
        # é¢„å¤„ç†
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(image_tensor)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            predicted_class_idx = torch.argmax(probabilities).item()
            confidence = probabilities[predicted_class_idx].item()
        
        predicted_class = self.class_names[predicted_class_idx]
        
        # æ˜¾ç¤ºç»“æœ
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        plt.imshow(original_image)
        plt.title(f'è¾“å…¥å›¾ç‰‡\né¢„æµ‹: {predicted_class} ({confidence*100:.2f}%)', fontsize=14)
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        # ç»˜åˆ¶ç½®ä¿¡åº¦
        colors = ['#ff9999' if i == predicted_class_idx else '#66b3ff' for i in range(len(self.class_names))]
        y_pos = np.arange(len(self.class_names))
        confidences = [probabilities[i].item() for i in range(len(self.class_names))]
        
        bars = plt.barh(y_pos, confidences, color=colors)
        plt.xlabel('ç½®ä¿¡åº¦', fontsize=12)
        plt.title('åˆ†ç±»ç½®ä¿¡åº¦', fontsize=14)
        plt.yticks(y_pos, self.class_names)
        plt.xlim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            width = bar.get_width()
            plt.text(width + 0.01, bar.get_y() + bar.get_height()/2, 
                    f'{width:.3f}', ha='left', va='center', fontsize=11)
        
        plt.tight_layout()
        plt.show()
        
        print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {predicted_class}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.4f}")
        
        return predicted_class, confidence

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("           M4 GPU çŒ«ç‹—åˆ†ç±»å™¨")
    print("=" * 60)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = M4CatDogTrainer()
    model, train_losses, val_accuracies = trainer.train()
    
    # ç»˜åˆ¶ç»“æœ
    if model is not None:
        trainer.plot_results(train_losses, val_accuracies)
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¿›è¡Œé¢„æµ‹ï¼š")
        print("predictor = M4Predictor('best_m4_model.pth')")
        print("result, confidence = predictor.predict('æ‚¨çš„å›¾ç‰‡è·¯å¾„.jpg')")

if __name__ == "__main__":
    main()