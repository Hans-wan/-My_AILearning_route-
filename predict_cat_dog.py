# predict_with_m4_model.py
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import os

class M4Predictor:
    def __init__(self, model_path='best_m4_model.pth'):
        # è®¾ç½®è®¾å¤‡
        if torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("ğŸ‰ ä½¿ç”¨M4 GPUè¿›è¡Œé¢„æµ‹")
        else:
            self.device = torch.device("cpu")
            print("âš¡ ä½¿ç”¨CPUè¿›è¡Œé¢„æµ‹")
        
        # åŠ è½½æ¨¡å‹
        try:
            checkpoint = torch.load(model_path, map_location=self.device)
            self.class_names = checkpoint['class_names']
            self.best_accuracy = checkpoint.get('accuracy', 0)
            
            # åˆ›å»ºæ¨¡å‹ç»“æ„ï¼ˆä½¿ç”¨ResNet50ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            self.model = models.resnet50(pretrained=False)
            num_features = self.model.fc.in_features
            self.model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(num_features, 1024),
                nn.ReLU(),
                nn.BatchNorm1d(1024),
                nn.Dropout(0.3),
                nn.Linear(1024, 512),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(512, len(self.class_names))
            )
            
            # åŠ è½½æƒé‡
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            self.model.eval()
            
            # æ•°æ®é¢„å¤„ç†
            self.transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            print(f"ğŸ“Š è®­ç»ƒå‡†ç¡®ç‡: {self.best_accuracy:.2f}%")
            print(f"ğŸ¯ è¯†åˆ«ç±»åˆ«: {self.class_names}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def predict(self, image_path):
        """é¢„æµ‹å•å¼ å›¾ç‰‡"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return None, None
            
            # åŠ è½½å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            original_image = np.array(image)
            
            print(f"ğŸ“· æ­£åœ¨åˆ†æå›¾ç‰‡: {os.path.basename(image_path)}")
            print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {image.size}")
            
            # é¢„å¤„ç†
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                predicted_class_idx = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_class_idx].item()
            
            predicted_class = self.class_names[predicted_class_idx]
            
            # æ˜¾ç¤ºç»“æœ
            self._display_results(original_image, predicted_class, confidence, probabilities)
            
            print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {predicted_class}")
            print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.4f} ({confidence*100:.2f}%)")
            
            # åˆ¤æ–­æ˜¯å¦é«˜ç½®ä¿¡åº¦
            if confidence > 0.8:
                print("ğŸ’ª é«˜ç½®ä¿¡åº¦é¢„æµ‹ï¼")
            elif confidence > 0.6:
                print("ğŸ‘ ä¸­ç­‰ç½®ä¿¡åº¦é¢„æµ‹")
            else:
                print("ğŸ¤” ä½ç½®ä¿¡åº¦é¢„æµ‹ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæ•°æ®")
            
            return predicted_class, confidence
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None, None

    def _display_results(self, image, predicted_class, confidence, probabilities):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        plt.figure(figsize=(13, 6))
        
        # æ˜¾ç¤ºåŸå›¾
        plt.subplot(1, 2, 1)
        plt.imshow(image)
        plt.title(f'M4æ¨¡å‹é¢„æµ‹ç»“æœ\né¢„æµ‹: {predicted_class}\nç½®ä¿¡åº¦: {confidence*100:.2f}%', 
                 fontsize=14, pad=15)
        plt.axis('off')
        
        # æ˜¾ç¤ºç½®ä¿¡åº¦æ¡å½¢å›¾
        plt.subplot(1, 2, 2)
        colors = ['#ff6b6b' if i == predicted_class else '#4ecdc4' 
                 for i in range(len(self.class_names))]
        
        confidences = [probabilities[i].item() for i in range(len(self.class_names))]
        bars = plt.bar(self.class_names, confidences, color=colors, alpha=0.8, width=0.6)
        
        plt.ylim(0, 1.1)
        plt.title('åˆ†ç±»ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, pad=15)
        plt.ylabel('ç½®ä¿¡åº¦', fontsize=12)
        plt.grid(True, axis='y', alpha=0.3)
        
        # åœ¨æ¡å½¢ä¸Šæ·»åŠ æ•°å€¼
        for bar, conf in zip(bars, confidences):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2, height + 0.02,
                    f'{conf:.3f}', ha='center', va='bottom', fontsize=12, 
                    fontweight='bold', color='black')
        
        # æ·»åŠ é˜ˆå€¼çº¿
        plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='é˜ˆå€¼ (0.5)')
        plt.legend()
        
        plt.tight_layout()
        plt.show()

    def predict_multiple(self, image_folder):
        """é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
        if not os.path.exists(image_folder):
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {image_folder}")
            return
        
        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')
        image_files = [f for f in os.listdir(image_folder) 
                      if f.lower().endswith(image_extensions)]
        
        if not image_files:
            print(f"âŒ åœ¨ {image_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return
        
        print(f"ğŸ“ åœ¨ {image_folder} ä¸­æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        print("å¼€å§‹æ‰¹é‡é¢„æµ‹...")
        
        results = []
        for i, image_file in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] å¤„ç†: {image_file}")
            image_path = os.path.join(image_folder, image_file)
            result, confidence = self.predict(image_path)
            if result is not None:
                results.append((image_file, result, confidence))
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        if results:
            self._show_statistics(results)

    def _show_statistics(self, results):
        """æ˜¾ç¤ºæ‰¹é‡é¢„æµ‹çš„ç»Ÿè®¡ç»“æœ"""
        print("\n" + "="*60)
        print("                 M4æ¨¡å‹æ‰¹é‡é¢„æµ‹ç»Ÿè®¡ç»“æœ")
        print("="*60)
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        from collections import Counter
        class_counter = Counter([result[1] for result in results])
        
        total_images = len(results)
        print(f"ğŸ“Š æ€»è®¡å¤„ç†å›¾ç‰‡: {total_images}å¼ ")
        print("\nåˆ†ç±»ç»“æœç»Ÿè®¡:")
        for class_name in self.class_names:
            count = class_counter.get(class_name, 0)
            percentage = (count / total_images) * 100 if total_images > 0 else 0
            print(f"  {class_name}: {count}å¼  ({percentage:.1f}%)")
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = [result[2] for result in results]
        avg_confidence = np.mean(confidences)
        max_confidence = np.max(confidences)
        min_confidence = np.min(confidences)
        
        print(f"\nğŸ“ˆ ç½®ä¿¡åº¦ç»Ÿè®¡:")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f} ({avg_confidence*100:.2f}%)")
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_confidence:.4f} ({max_confidence*100:.2f}%)")
        print(f"  æœ€ä½ç½®ä¿¡åº¦: {min_confidence:.4f} ({min_confidence*100:.2f}%)")
        
        # é«˜ç½®ä¿¡åº¦å›¾ç‰‡ç»Ÿè®¡
        high_conf = len([c for c in confidences if c > 0.8])
        medium_conf = len([c for c in confidences if 0.6 < c <= 0.8])
        low_conf = len([c for c in confidences if c <= 0.6])
        
        print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        print(f"  é«˜ç½®ä¿¡åº¦ (>0.8): {high_conf}å¼  ({(high_conf/total_images)*100:.1f}%)")
        print(f"  ä¸­ç½®ä¿¡åº¦ (0.6-0.8): {medium_conf}å¼  ({(medium_conf/total_images)*100:.1f}%)")
        print(f"  ä½ç½®ä¿¡åº¦ (â‰¤0.6): {low_conf}å¼  ({(low_conf/total_images)*100:.1f}%)")

def test_with_sample_images():
    """ä½¿ç”¨ç¤ºä¾‹å›¾ç‰‡æµ‹è¯•æ¨¡å‹"""
    print("ğŸ±ğŸ¶ æµ‹è¯•M4çŒ«ç‹—åˆ†ç±»æ¨¡å‹")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists('best_m4_model.pth'):
        print("âŒ æ¨¡å‹æ–‡ä»¶ 'best_m4_model.pth' ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨å½“å‰ç›®å½•")
        return
    
    # åˆ›å»ºé¢„æµ‹å™¨
    try:
        predictor = M4Predictor('best_m4_model.pth')
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹: {e}")
        return
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•å›¾ç‰‡
    test_images = []
    for ext in ['.jpg', '.jpeg', '.png']:
        test_images.extend([f for f in os.listdir('.') if f.lower().endswith(ext)])
    
    if test_images:
        print(f"\nğŸ“· å‘ç° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡:")
        for img in test_images:
            print(f"  - {img}")
        
        choice = input("\næ˜¯å¦æµ‹è¯•è¿™äº›å›¾ç‰‡? (y/n): ").strip().lower()
        if choice == 'y':
            for img in test_images:
                print(f"\n{'='*50}")
                predictor.predict(img)
    else:
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("1. å°†çŒ«ç‹—å›¾ç‰‡æ”¾åœ¨å½“å‰ç›®å½•")
        print("2. è¿è¡Œ: python predict_with_m4_model.py")
        print("3. æˆ–è€…è¿è¡Œä¸‹é¢çš„äº¤äº’æ¨¡å¼")

def interactive_mode():
    """äº¤äº’å¼é¢„æµ‹æ¨¡å¼"""
    print("\nğŸ” M4çŒ«ç‹—åˆ†ç±»å™¨ - äº¤äº’æ¨¡å¼")
    
    try:
        predictor = M4Predictor('best_m4_model.pth')
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹: {e}")
        return
    
    while True:
        print("\n" + "="*50)
        print("è¯·é€‰æ‹©æ“ä½œ:")
        print("1. é¢„æµ‹å•å¼ å›¾ç‰‡")
        print("2. é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡") 
        print("3. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()
        
        if choice == '1':
            image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
            if image_path and os.path.exists(image_path):
                predictor.predict(image_path)
            else:
                print("âŒ å›¾ç‰‡è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨")
        
        elif choice == '2':
            folder_path = input("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
            if folder_path and os.path.exists(folder_path):
                predictor.predict_multiple(folder_path)
            else:
                print("âŒ æ–‡ä»¶å¤¹è·¯å¾„æ— æ•ˆæˆ–ä¸å­˜åœ¨")
        
        elif choice == '3':
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨M4çŒ«ç‹—åˆ†ç±»å™¨ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    print("=" * 60)
    print("           M4çŒ«ç‹—åˆ†ç±»é¢„æµ‹å™¨")
    print("=" * 60)
    
    # é¦–å…ˆæµ‹è¯•ç¤ºä¾‹å›¾ç‰‡
    test_with_sample_images()
    
    # ç„¶åè¿›å…¥äº¤äº’æ¨¡å¼
    interactive_mode()